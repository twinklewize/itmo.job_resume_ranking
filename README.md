# Datasets

В качестве датасетов для обучения были использованы данные с сайта [Работа России](https://trudvsem.ru/opendata/datasets):
- Резюме из ЕЦП «Работа в России»
- Вакансии всех регионов России из ЕЦП «Работа в России»

## Preprocessing

1. Из каждого из датасетов было выбрано 30 000 случайных строк
2. Табличные данные были преобразованы в текстовый формат
3. Для резюме были использованы следующие features: `positionName, workExperienceList, educationList, additionalEducationList, hardSkills, softSkills, otherCertificates, worldskills`
4. Для вакансий были использованы следующие features: `vacancy_name, position_responsibilities, position_requirements, additional_requirements, hardSkills, softSkills`
5. Из текстов были удалены стопслова и лишние символы, они были приведены в нижний регистр, была осуществлена лемматизация и токенизация

# Experiments

1. Doc2Vec (`gensim`)
2. BERT (`DeepPavlov/rubert-base-cased`)

Метрика ранжирования cosine_similarity, theshold = 0.5

### Doc2Vec

Был обучен на 60 000 токенизированных текстов.

Использовались следующие гиперпараметры:
```
vector_size=64
min_count=6
epochs=100
alpha=0.001
```

1. Создаем с помощью модели эмбеддинги вдохдящих текстов
2. Сравниваем эмбеддинги через cosine_similarity (`sklearn`)
3. Приводим оценку к процентному формату
4. Сортируем по уменьшению оценки

> Работает достаточно хорошо, но бывают неточности в ранжировании.

### BERT

Использован zero-shot подход. Из каждого текста получаем эмбеддинг. Процесс формирования оценки не отличается.

> Работает хуже чем Doc2Vec, но может быть полезен при оценке редких вакансий/резюме.

### Doc2Vec + BERT

1. Формируем эмбеддинги, как в прошлых вариантах
2. Изменяем эмбеддинги в соответствии с указанным весом (в нашем случае уменьшаем вес BERT эмбеддингов)
3. Конкатенируем эмбеддинги

> Является лучшим из 3 подходов, так как объединяет возможность работать с редкими вакансиями/резюме и хорошее качество ранжирования 

# How to launch?
1. update `REPOSITORY_PATH` in `src/config.py`
2. run `pip install -r requirements.txt`
3. run `gradio src/app.py`

![Empty UI](img/gradio_ui.png)


# Result
1. Как итоговое решение мы предлагаем использовать Doc2Vec + BERT
2. Данное решение является самым точным из тех, с которыми производились эксперименты
3. При выводе данного решения в production есть возможность формировать все эмбеддинги вакансий и резюме заранее, и при поиске использовать уже сформированные эмбеддинги, что позволяет масштабировать решение под любое количество резюме и вакансий
